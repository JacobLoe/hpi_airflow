# docker build -f Dockerfile_airflow -t jacobloe/airflow:0.1 .
# docker run --rm -it -v airflow_cache:/data -v /var/run/docker.sock:/var/run/docker.sock -p 8080:8080 --name airflow jacobloe/airflow:0.1
# --entrypoint /bin/bash
# airflow scheduler & airflow webserver -p 8080
# docker volume create --driver local --opt type=none --opt device=/home/jacob/Downloads/hpi/static/data --opt o=bind airflow_cache

# docker run --rm -it -v airflow_cache:/data --entrypoint /bin/bash jacobloe/shot_detection:0.7
#FROM python:3.8.3
FROM python:3.8-slim-buster

ENV DEBIAN_FRONTEND noninteractive

RUN apt-get update && apt-get install -y build-essential

# install airflow for python 3.8
RUN pip3 install --trusted-host pypi.python.org apache-airflow==1.10.12 --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-1.10.12/constraints-3.8.txt"
# is needed for docker_operator.py
RUN pip3 install docker==4.3.1
# FIXME vim is not supposed to be in the final dockerfile
RUN apt update && apt install -y vim

#
#RUN apt-get update
#RUN apt-get -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common
#RUN curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -
#RUN add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"

#RUN apt-get update
#RUN apt-get -y install docker-ce-cli

# initialise the database for airflow
# this also creates the airflow folder with the configuration in root
RUN airflow initdb

# edit the airflow configuration file to let airflow exclude example dags
RUN sed -i '/load_examples = True/c load_examples = False' /root/airflow/airflow.cfg
# now all dags can be triggered without needing to unpause them first
RUN sed -i '/dags_are_paused_at_creation = True/c dags_are_paused_at_creation = False' /root/airflow/airflow.cfg
# FIXME this done temporarily to allow all connections to the server, ideally this would be changed to work with username/password
RUN sed -i '/auth_backend = airflow.api.auth.backend.deny_all/c auth_backend = airflow.api.auth.backend.default' /root/airflow/airflow.cfg

# create the folder in which airflow is lokking for dags
RUN mkdir /root/airflow/dags

# dag scripts
COPY airflow_shotdetection.py /root/airflow/dags
# FIXME copy remaining dag scripts

# copy the scripts that are used by all dags for tasks
COPY docker_operator.py /root/airflow/dags
COPY get_video.py /root/airflow/dags

# initialising the database again now excludes the example dags and adds the new dags as specified in the airflow.cfg
RUN airflow initdb

# expose port for the airflow webserver
EXPOSE 8080

VOLUME "/data"

WORKDIR /root

# start the scheduler so dags can be triggered and start the webserver to allow supervision
ENTRYPOINT airflow scheduler & airflow webserver -p 8080